下载wget命令:yum install -y wget

高效去重:BitMap：海量数据的去重

Flink CDC监听的数据上传kafka数据和jar包上传的kafka数据是有区别的，在敲FlinkSQL时就需要使用两种不同的方法来解决。传统的kafka数据比较清楚，但Flink CDC上传的kafka不是很了解，目前正在解决和理解中。

一到一千万随机抽取一个数据，在不使用一些插件的状态下，比如（不能排序、不能聚合、不能join等）
            可以通过sum把所有数加到一起，减去随机抽取的所有数，就可以得到自己想要的随机抽取的数了。

九个苹果，其中八个苹果一样重，要怎样才能找到那个不一样的苹果呢，至少需要几次
            至少需要2次，可以把苹果按照3v3的方式解决。

HDFS的写流程：
• client 发起文件上传请求，通过 RPC 与 NameNode 建立通讯，NameNode 检查目标文件是否已存在，父目录是否存在，返回是否可以上传；
• client 请求第一个 block 该传输到哪些 DataNode 服务器上；
• NameNode 根据配置文件中指定的备份数量及副本放置策略进行文件分配，返回可用的 DataNode 的地址，如：A，B，C；
• client 请求3台 DataNode 中的一台A上传数据（本质上是一个 RPC 调用，建立 pipeline），A收到请求会继续调用B，然后B调用C，将整个 pipeline 建立完成，后逐级返回 client；
• client 开始往A上传第一个 block（先从磁盘读取数据放到一个本地内存缓存），以 packet 为单位（默认64K），A收到一个 packet 就会传给B，B传给C；A每传一个 packet 会放入一个应答队列等待应答。
• 数据被分割成一个个 packet 数据包在 pipeline 上依次传输，在 pipeline 反方向上，逐个发送 ack（ack 应答机制），最终由pipeline中第一个 DataNode 节点A将 pipeline ack 发送给client;
• 当一个 block 传输完成之后，client 再次请求 NameNode 上传第二个 block 到服务器

Hadoop的调度器:
            比较流行的三种调度器有:默认调度器（FIFO）、计算能力调度器（Capacity Scheduler）(容量调度器)、公平调度器（Fair Scheduler）