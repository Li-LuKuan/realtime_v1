你好，面试官，
        我叫李路宽，从事大数据开发5年了，比较擅长流批一体的开发，会java、python的语言，python主要运用于爬虫。

多练三性六讲的话语

Flink断点续传:是基于offset,flink的checkpoint机制是实现断点续传的关键,
    Checkpoint 是一种分布式快照，它可以捕获作业的状态，包括数据源（如 Kafka）的 Offset。
    例如我们下载软件软件期间暂停操作就需要一个断点续传,直接从断点处继续续传

实时业务的开发：
//  1.ETL清洗主流数据
SingleOutputStreamOperator<JSONObject> etlStream = etl(dataStreamSource);
// 2.通过CDC读取配置表,并行度只能是1
DataStreamSource<String> processStream = env.fromSource(FlinkSourceUtil.getMysqlSource(Constant.PROCESS_DATABASE, Constant.PROCESS_DIM_TABLE_NAME), WatermarkStrategy.noWatermarks(), "cdc_stream").setParallelism(1);
// 3.在Hbase建表
SingleOutputStreamOperator<TableProcessDim> createTableStream = createTable(processStream);
// 4.主流数据和广播进行连接处理
MapStateDescriptor<String,TableProcessDim> mapDescriptor = new MapStateDescriptor<String,TableProcessDim>("broadcast_state",String.class,TableProcessDim.class);
BroadcastStream<TableProcessDim> broadcastStream = createTableStream.broadcast(mapDescriptor);
SingleOutputStreamOperator<Tuple2<JSONObject, TableProcessDim>> processBroadCastStream = etlStream.connect(broadcastStream).process(new DimProcessFunction(mapDescriptor));
// 5.过滤字段
SingleOutputStreamOperator<Tuple2<JSONObject, TableProcessDim>> filterStream = getFilterStream(processBroadCastStream);
// 6.写入Hbase
filterStream.addSink(new DimSinkFunction());